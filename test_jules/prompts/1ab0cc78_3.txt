You are a Senior Java Software Architect and an expert in Code Refactoring. I am providing you with a Java "God Class".
Your Goal: Perform an Extract Class refactoring to improve maintainability and adhere to the Single ResponsibilityPrinciple.
Constraints:
-Identify the specific responsibilities to be extracted.
-Output the FULL code for the new classes (no gaps or placeholders).
-Output the FULL code for the modified original class.
-Do not use placeholders (e.g., do not write // ... existing code).
Input Code:
god class code:/*/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.accumulo.core.client.rfile;

import java.io.IOException;
import java.util.HashMap;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Objects;

import org.apache.accumulo.core.client.Scanner;
import org.apache.accumulo.core.client.rfile.RFile.ScannerFSOptions;
import org.apache.accumulo.core.client.rfile.RFile.ScannerOptions;
import org.apache.accumulo.core.data.Range;
import org.apache.accumulo.core.security.Authorizations;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;

import com.google.common.base.Preconditions;

class RFileScannerBuilder implements RFile.InputArguments, RFile.ScannerFSOptions {

  static class InputArgs extends FSConfArgs {
    private FencedPath[] rFiles;
    private RFileSource[] sources;

    InputArgs(String... files) {
      this.rFiles = new FencedPath[files.length];
      for (int i = 0; i < files.length; i++) {
        this.rFiles[i] = new FencedPath(new Path(files[i]), new Range());
      }
    }

    InputArgs(FencedPath... files) {
      this.rFiles = files;
    }

    InputArgs(RFileSource... sources) {
      this.sources = sources;
    }

    RFileSource[] getSources() throws IOException {
      if (sources == null) {
        sources = new RFileSource[rFiles.length];
        for (int i = 0; i < rFiles.length; i++) {
          final Path path = rFiles[i].getPath();
          sources[i] = new RFileSource(getFileSystem().open(path),
              getFileSystem().getFileStatus(path).getLen(), rFiles[i].getFence());
        }
      } else {
        for (int i = 0; i < sources.length; i++) {
          if (!(sources[i].getInputStream() instanceof FSDataInputStream)) {
            sources[i] = new RFileSource(new FSDataInputStream(sources[i].getInputStream()),
                sources[i].getLength(), rFiles[i].getFence());
          }
        }
      }

      return sources;
    }
  }

  private RFileScanner.Opts opts = new RFileScanner.Opts();

  @Override
  public ScannerOptions withoutSystemIterators() {
    opts.useSystemIterators = false;
    return this;
  }

  @Override
  public ScannerOptions withAuthorizations(Authorizations auths) {
    Objects.requireNonNull(auths);
    opts.auths = auths;
    return this;
  }

  @Override
  public ScannerOptions withDataCache(long cacheSize) {
    Preconditions.checkArgument(cacheSize > 0);
    opts.dataCacheSize = cacheSize;
    return this;
  }

  @Override
  public ScannerOptions withIndexCache(long cacheSize) {
    Preconditions.checkArgument(cacheSize > 0);
    opts.indexCacheSize = cacheSize;
    return this;
  }

  @Override
  public Scanner build() {
    return new RFileScanner(opts);
  }

  @Override
  public ScannerOptions withFileSystem(FileSystem fs) {
    Objects.requireNonNull(fs);
    opts.in.fs = fs;
    return this;
  }

  @Override
  public ScannerOptions from(RFileSource... inputs) {
    Objects.requireNonNull(inputs);
    opts.in = new InputArgs(inputs);
    return this;
  }

  @Override
  public ScannerFSOptions from(String... files) {
    Objects.requireNonNull(files);
    opts.in = new InputArgs(files);
    return this;
  }

  @Override
  public ScannerFSOptions from(FencedPath... files) {
    Objects.requireNonNull(files);
    opts.in = new InputArgs(files);
    return this;
  }

  @Override
  public ScannerOptions withTableProperties(Iterable<Entry<String,String>> tableConfig) {
    Objects.requireNonNull(tableConfig);
    this.opts.tableConfig = new HashMap<>();
    for (Entry<String,String> entry : tableConfig) {
      this.opts.tableConfig.put(entry.getKey(), entry.getValue());
    }
    return this;
  }

  @Override
  public ScannerOptions withTableProperties(Map<String,String> tableConfig) {
    Objects.requireNonNull(tableConfig);
    this.opts.tableConfig = new HashMap<>(tableConfig);
    return this;
  }

  @Override
  public ScannerOptions withBounds(Range range) {
    Objects.requireNonNull(range);
    this.opts.bounds = range;
    return this;
  }

}*/
dependencies:/*/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.accumulo.core.client.rfile;

import java.io.IOException;
import java.io.OutputStream;
import java.util.Collection;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Objects;
import java.util.function.Predicate;

import org.apache.accumulo.core.client.Scanner;
import org.apache.accumulo.core.client.admin.TableOperations;
import org.apache.accumulo.core.client.sample.SamplerConfiguration;
import org.apache.accumulo.core.client.summary.Summarizer;
import org.apache.accumulo.core.client.summary.SummarizerConfiguration;
import org.apache.accumulo.core.client.summary.Summary;
import org.apache.accumulo.core.client.summary.Summary.FileStatistics;
import org.apache.accumulo.core.conf.Property;
import org.apache.accumulo.core.data.Key;
import org.apache.accumulo.core.data.Range;
import org.apache.accumulo.core.metadata.AbstractTabletFile;
import org.apache.accumulo.core.security.Authorizations;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;

/**
 * RFile is Accumulo's internal storage format for Key Value pairs. This class is a Factory that
 * enables creating a {@link Scanner} for reading and a {@link RFileWriter} for writing Rfiles.
 *
 * <p>
 * The {@link Scanner} created by this class makes it easy to experiment with real data from a live
 * system on a developers workstation. Also the {@link Scanner} can be used to write tools to
 * analyze Accumulo's raw data.
 *
 * @since 1.8.0
 */
public class RFile {

  /**
   * This is an intermediate interface in a larger builder pattern. Supports setting the required
   * input sources for reading a RFile.
   *
   * @since 1.8.0
   */
  public interface InputArguments {
    /**
     * Specify RFiles to read from. When multiple inputs are specified the {@link Scanner}
     * constructed will present a merged view.
     *
     * @param inputs one or more RFiles to read.
     * @return this
     */
    ScannerOptions from(RFileSource... inputs);

    /**
     * Specify RFiles to read from. When multiple are specified the {@link Scanner} constructed will
     * present a merged view.
     *
     * @param files one or more RFiles to read.
     * @return this
     */
    ScannerFSOptions from(String... files);

    /**
     * Specify FencedPath files to read from. When multiple are specified the {@link Scanner}
     * constructed will present a merged view.
     *
     * @param files one or more FencedPaths to read.
     * @return this
     *
     * @since 3.1.0
     */
    ScannerFSOptions from(FencedPath... files);

    /**
     * @since 3.1.0
     */
    class FencedPath {
      private final Path path;
      private final Range fence;

      public FencedPath(Path path, Range fence) {
        this.path = Objects.requireNonNull(path);
        this.fence = AbstractTabletFile.requireRowRange(fence);
      }

      public Path getPath() {
        return path;
      }

      public Range getFence() {
        return fence;
      }
    }
  }

  /**
   * This is an intermediate interface in a larger builder pattern. Enables optionally setting a
   * FileSystem to read RFile(s) from.
   *
   * @since 1.8.0
   */
  public interface ScannerFSOptions extends ScannerOptions {
    /**
     * Optionally provide a FileSystem to open RFiles. If not specified, the FileSystem will be
     * constructed using configuration on the classpath.
     *
     * @param fs use this FileSystem to open files.
     * @return this
     */
    ScannerOptions withFileSystem(FileSystem fs);
  }

  /**
   * This is an intermediate interface in a larger builder pattern. Supports setting optional
   * parameters for reading RFile(s) and building a scanner over RFile(s).
   *
   * @since 1.8.0
   */
  public interface ScannerOptions {

    /**
     * By default the {@link Scanner} created will setup the default Accumulo system iterators. The
     * iterators do things like the following :
     *
     * <ul>
     * <li>Suppress deleted data</li>
     * <li>Filter based on @link {@link Authorizations}</li>
     * <li>Filter columns specified by functions like {@link Scanner#fetchColumn(Text, Text)} and
     * {@link Scanner#fetchColumnFamily(Text)}</li>
     * </ul>
     *
     * <p>
     * Calling this method will turn off these system iterators and allow reading the raw data in an
     * RFile. When reading the raw data, delete data and delete markers may be seen. Delete markers
     * are {@link Key}s with the delete flag set.
     *
     * <p>
     * Disabling system iterators will cause {@link #withAuthorizations(Authorizations)},
     * {@link Scanner#fetchColumn(Text, Text)}, and {@link Scanner#fetchColumnFamily(Text)} to throw
     * runtime exceptions.
     *
     * @return this
     */
    ScannerOptions withoutSystemIterators();

    /**
     * The authorizations passed here will be used to filter Keys, from the {@link Scanner}, based
     * on the content of the column visibility field.
     *
     * @param auths scan with these authorizations
     * @return this
     */
    ScannerOptions withAuthorizations(Authorizations auths);

    /**
     * Enabling this option will cache RFiles data in memory. This option is useful when doing lots
     * of random accesses.
     *
     * @param cacheSize the size of the data cache in bytes.
     * @return this
     */
    ScannerOptions withDataCache(long cacheSize);

    /**
     * Enabling this option will cache RFiles indexes in memory. Index data within a RFile is used
     * to find data when seeking to a {@link Key}. This option is useful when doing lots of random
     * accesses.
     *
     * @param cacheSize the size of the index cache in bytes.
     * @return this
     */
    ScannerOptions withIndexCache(long cacheSize);

    /**
     * This option allows limiting the {@link Scanner} from reading data outside of a given range. A
     * scanner will not see any data outside of this range even if the RFile(s) have data outside
     * the range.
     *
     * @return this
     */
    ScannerOptions withBounds(Range range);

    /**
     * Construct the {@link Scanner} with iterators specified in a tables properties. Properties for
     * a table can be obtained by calling {@link TableOperations#getProperties(String)}. Any
     * property that impacts file behavior regardless of whether it has the
     * {@link Property#TABLE_PREFIX} may be accepted and used. For example, cache and crypto
     * properties could be passed here.
     *
     * @param props iterable over Accumulo table key value properties.
     * @return this
     */
    ScannerOptions withTableProperties(Iterable<Entry<String,String>> props);

    /**
     * @see #withTableProperties(Iterable) Any property that impacts file behavior regardless of
     *      whether it has the {@link Property#TABLE_PREFIX} may be accepted and used. For example,
     *      cache and crypto properties could be passed here.
     * @param props a map instead of an Iterable
     * @return this
     */
    ScannerOptions withTableProperties(Map<String,String> props);

    /**
     * @return a Scanner over RFile using the specified options.
     */
    Scanner build();
  }

  /**
   * Entry point for building a new {@link Scanner} over one or more RFiles.
   */
  public static InputArguments newScanner() {
    return new RFileScannerBuilder();
  }

  /**
   * This is an intermediate interface in a larger builder pattern. Supports setting the required
   * input sources for reading summary data from an RFile.
   *
   * @since 2.0.0
   */
  public interface SummaryInputArguments {
    /**
     * Specify RFiles to read from. When multiple inputs are specified the summary data will be
     * merged.
     *
     * @param inputs one or more RFiles to read.
     * @return this
     */
    SummaryOptions from(RFileSource... inputs);

    /**
     * Specify RFiles to read from. When multiple are specified the summary data will be merged.
     *
     * @param files one or more RFiles to read.
     * @return this
     */
    SummaryFSOptions from(String... files);
  }

  /**
   * This is an intermediate interface in a larger builder pattern. Enables optionally setting a
   * FileSystem to read RFile summary data from.
   *
   * @since 2.0.0
   */
  public interface SummaryFSOptions extends SummaryOptions {
    /**
     * Optionally provide a FileSystem to open RFiles. If not specified, the FileSystem will be
     * constructed using configuration on the classpath.
     *
     * @param fs use this FileSystem to open files.
     * @return this
     */
    SummaryOptions withFileSystem(FileSystem fs);
  }

  /**
   * This is an intermediate interface in a large builder pattern. Allows setting options for
   * retrieving summary data.
   *
   * @since 2.0.0
   */
  public interface SummaryOptions {
    /**
     * Retrieve summaries with provided tables properties. Properties for a table can be obtained by
     * calling {@link TableOperations#getProperties(String)}. Any property that impacts file
     * behavior regardless of whether it has the {@link Property#TABLE_PREFIX} may be accepted and
     * used. For example, cache and crypto properties could be passed here.
     *
     * @param props iterable over Accumulo table key value properties.
     * @return this
     */
    SummaryOptions withTableProperties(Iterable<Entry<String,String>> props);

    /**
     * @see #withTableProperties(Iterable) Any property that impacts file behavior regardless of
     *      whether it has the {@link Property#TABLE_PREFIX} may be accepted and used. For example,
     *      cache and crypto properties could be passed here.
     * @param props a map instead of an Iterable
     * @return this
     */
    SummaryOptions withTableProperties(Map<String,String> props);

    /**
     * This method allows retrieving a subset of summary data from a file. If a file has lots of
     * separate summaries, reading a subset may be faster.
     *
     * @param summarySelector Only read summary data that was generated with configuration that this
     *        predicate matches.
     * @return this
     */
    SummaryOptions selectSummaries(Predicate<SummarizerConfiguration> summarySelector);

    /**
     * Summary data may possibly be stored at a more granular level than the entire file. However
     * there is no guarantee of this. If the data was stored at a more granular level, then this
     * will get a subset of the summary data. The subset will very likely be an inaccurate
     * approximation.
     *
     * @param startRow A non-null start row. The startRow is used exclusively.
     * @return this
     *
     * @see FileStatistics#getExtra()
     */
    SummaryOptions startRow(Text startRow);

    /**
     * @param startRow UTF-8 encodes startRow. The startRow is used exclusively.
     * @return this
     * @see #startRow(Text)
     */
    SummaryOptions startRow(CharSequence startRow);

    /**
     * Summary data may possibly be stored at a more granular level than the entire file. However
     * there is no guarantee of this. If the data was stored at a more granular level, then this
     * will get a subset of the summary data. The subset will very likely be an inaccurate
     * approximation.
     *
     * @param endRow A non-null end row. The end row is used inclusively.
     * @return this
     *
     * @see FileStatistics#getExtra()
     */
    SummaryOptions endRow(Text endRow);

    /**
     * @param endRow UTF-8 encodes endRow. The end row is used inclusively.
     * @return this
     * @see #endRow(Text)
     */
    SummaryOptions endRow(CharSequence endRow);

    /**
     * Reads summary data from file.
     *
     * @return The summary data in the file that satisfied the selection criteria.
     */
    Collection<Summary> read() throws IOException;
  }

  /**
   * Entry point for reading summary data from RFiles.
   *
   * @since 2.0.0
   */
  public static SummaryInputArguments summaries() {
    return new RFileSummariesRetriever();
  }

  /**
   * This is an intermediate interface in a larger builder pattern. Supports setting the required
   * output sink to write a RFile to. The filename parameter requires the ".rf" extension.
   *
   * @since 1.8.0
   */
  public interface OutputArguments {
    /**
     * @param filename name of file to write RFile data, ending with the ".rf" extension
     * @return this
     */
    WriterFSOptions to(String filename);

    /**
     * @param out output stream to write RFile data
     * @return this
     */
    WriterOptions to(OutputStream out);
  }

  /**
   * This is an intermediate interface in a larger builder pattern. Enables optionally setting a
   * FileSystem to write to.
   *
   * @since 1.8.0
   */
  public interface WriterFSOptions extends WriterOptions {
    /**
     * Optionally provide a FileSystem to open a file to write a RFile. If not specified, the
     * FileSystem will be constructed using configuration on the classpath.
     *
     * @param fs use this FileSystem to open files.
     * @return this
     */
    WriterOptions withFileSystem(FileSystem fs);
  }

  /**
   * This is an intermediate interface in a larger builder pattern. Supports setting optional
   * parameters for creating a RFile and building a RFileWriter.
   *
   * @since 1.8.0
   */
  public interface WriterOptions {

    /**
     * Enable generating summary data in the created RFile by running {@link Summarizer}'s based on
     * the specified configuration.
     *
     * @param summarizerConf Configuration for summarizer to run.
     * @since 2.0.0
     */
    default WriterOptions withSummarizers(SummarizerConfiguration... summarizerConf) {
      throw new UnsupportedOperationException();
    }

    /**
     * An option to store sample data in the generated RFile.
     *
     * @param samplerConf configuration to use when generating sample data.
     * @throws IllegalArgumentException if table properties were previously specified and the table
     *         properties also specify a sampler.
     * @return this
     */
    WriterOptions withSampler(SamplerConfiguration samplerConf);

    /**
     * Create an RFile using the same configuration as an Accumulo table. Properties for a table can
     * be obtained by calling {@link TableOperations#getProperties(String)}. Any property that
     * impacts file behavior regardless of whether it has the {@link Property#TABLE_PREFIX} may be
     * accepted and used. For example, cache and crypto properties could be passed here.
     *
     * @param props iterable over Accumulo table key value properties.
     * @throws IllegalArgumentException if sampler was previously specified and the table properties
     *         also specify a sampler.
     * @return this
     */
    WriterOptions withTableProperties(Iterable<Entry<String,String>> props);

    /**
     * @see #withTableProperties(Iterable)
     */
    WriterOptions withTableProperties(Map<String,String> props);

    /**
     * @param maxSize As keys are added to an RFile the visibility field is validated. Validating
     *        the visibility field requires parsing it. In order to make validation faster,
     *        previously seen visibilities are cached. This option allows setting the maximum size
     *        of this cache.
     * @return this
     */
    WriterOptions withVisibilityCacheSize(int maxSize);

    /**
     * @return a new RfileWriter created with the options previously specified.
     */
    RFileWriter build() throws IOException;
  }

  /**
   * Entry point for creating a new RFile writer.
   */
  public static OutputArguments newWriter() {
    return new RFileWriterBuilder();
  }
}
---------
/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.accumulo.core.client.rfile;

import java.io.IOException;
import java.io.UncheckedIOException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.List;
import java.util.Map;
import java.util.Map.Entry;
import java.util.Set;
import java.util.SortedSet;
import java.util.function.Supplier;

import org.apache.accumulo.core.client.IteratorSetting;
import org.apache.accumulo.core.client.Scanner;
import org.apache.accumulo.core.client.rfile.RFileScannerBuilder.InputArgs;
import org.apache.accumulo.core.client.sample.SamplerConfiguration;
import org.apache.accumulo.core.clientImpl.ScannerOptions;
import org.apache.accumulo.core.conf.AccumuloConfiguration;
import org.apache.accumulo.core.conf.ConfigurationCopy;
import org.apache.accumulo.core.conf.DefaultConfiguration;
import org.apache.accumulo.core.conf.Property;
import org.apache.accumulo.core.crypto.CryptoFactoryLoader;
import org.apache.accumulo.core.data.ByteSequence;
import org.apache.accumulo.core.data.Column;
import org.apache.accumulo.core.data.Key;
import org.apache.accumulo.core.data.Range;
import org.apache.accumulo.core.data.Value;
import org.apache.accumulo.core.file.blockfile.cache.impl.BlockCacheConfiguration;
import org.apache.accumulo.core.file.blockfile.cache.impl.BlockCacheManagerFactory;
import org.apache.accumulo.core.file.blockfile.impl.BasicCacheProvider;
import org.apache.accumulo.core.file.blockfile.impl.CachableBlockFile.CachableBuilder;
import org.apache.accumulo.core.file.blockfile.impl.CacheProvider;
import org.apache.accumulo.core.file.rfile.RFile;
import org.apache.accumulo.core.file.rfile.RFile.Reader;
import org.apache.accumulo.core.iterators.IteratorAdapter;
import org.apache.accumulo.core.iterators.IteratorEnvironment;
import org.apache.accumulo.core.iterators.IteratorUtil.IteratorScope;
import org.apache.accumulo.core.iterators.SortedKeyValueIterator;
import org.apache.accumulo.core.iteratorsImpl.IteratorBuilder;
import org.apache.accumulo.core.iteratorsImpl.IteratorConfigUtil;
import org.apache.accumulo.core.iteratorsImpl.system.MultiIterator;
import org.apache.accumulo.core.iteratorsImpl.system.SystemIteratorUtil;
import org.apache.accumulo.core.sample.impl.SamplerConfigurationImpl;
import org.apache.accumulo.core.security.Authorizations;
import org.apache.accumulo.core.spi.cache.BlockCache;
import org.apache.accumulo.core.spi.cache.BlockCacheManager;
import org.apache.accumulo.core.spi.cache.CacheEntry;
import org.apache.accumulo.core.spi.cache.CacheType;
import org.apache.accumulo.core.spi.crypto.CryptoEnvironment;
import org.apache.accumulo.core.spi.crypto.CryptoService;
import org.apache.accumulo.core.util.LocalityGroupUtil;
import org.apache.hadoop.fs.FSDataInputStream;
import org.apache.hadoop.io.Text;

import com.google.common.base.Preconditions;

class RFileScanner extends ScannerOptions implements Scanner {

  private static final byte[] EMPTY_BYTES = new byte[0];
  private static final Range EMPTY_RANGE = new Range();

  private Range range;
  private BlockCacheManager blockCacheManager = null;
  private BlockCache dataCache = null;
  private BlockCache indexCache = null;
  private Opts opts;
  private int batchSize = 1000;
  private long readaheadThreshold = 3;
  private AccumuloConfiguration tableConf;
  private CryptoService cryptoService;

  static class Opts {
    InputArgs in;
    Authorizations auths = Authorizations.EMPTY;
    long dataCacheSize;
    long indexCacheSize;
    boolean useSystemIterators = true;
    public HashMap<String,String> tableConfig;
    Range bounds;
  }

  // This cache exist as a hack to avoid leaking decompressors. When the RFile code is not given a
  // cache it reads blocks directly from the decompressor. However if a user does not read all data
  // for a scan this can leave a BCFile block open and a decompressor allocated.
  //
  // By providing a cache to the RFile code it forces each block to be read into memory. When a
  // block is accessed the entire thing is read into memory immediately allocating and deallocating
  // a decompressor. If the user does not read all data, no decompressors are left allocated.
  private static class NoopCache implements BlockCache {

    @Override
    public CacheEntry cacheBlock(String blockName, byte[] buf) {
      return null;
    }

    @Override
    public CacheEntry getBlock(String blockName) {
      return null;
    }

    @Override
    public long getMaxHeapSize() {
      return getMaxSize();
    }

    @Override
    public long getMaxSize() {
      return Integer.MAX_VALUE;
    }

    @Override
    public Stats getStats() {
      return new BlockCache.Stats() {
        @Override
        public long hitCount() {
          return 0L;
        }

        @Override
        public long requestCount() {
          return 0L;
        }
      };
    }

    @Override
    public CacheEntry getBlock(String blockName, Loader loader) {
      Map<String,Loader> depLoaders = loader.getDependencies();
      Map<String,byte[]> depData;

      switch (depLoaders.size()) {
        case 0:
          depData = Collections.emptyMap();
          break;
        case 1:
          Entry<String,Loader> entry = depLoaders.entrySet().iterator().next();
          depData = Collections.singletonMap(entry.getKey(),
              getBlock(entry.getKey(), entry.getValue()).getBuffer());
          break;
        default:
          depData = new HashMap<>();
          depLoaders.forEach((k, v) -> depData.put(k, getBlock(k, v).getBuffer()));
      }

      byte[] data = loader.load(Integer.MAX_VALUE, depData);

      return new CacheEntry() {

        @Override
        public byte[] getBuffer() {
          return data;
        }

        @Override
        public <T extends Weighable> T getIndex(Supplier<T> supplier) {
          return null;
        }

        @Override
        public void indexWeightChanged() {}
      };
    }
  }

  RFileScanner(Opts opts) {
    if (!opts.auths.equals(Authorizations.EMPTY) && !opts.useSystemIterators) {
      throw new IllegalArgumentException(
          "Set authorizations and specified not to use system iterators");
    }

    this.opts = opts;
    if (opts.tableConfig != null && !opts.tableConfig.isEmpty()) {
      ConfigurationCopy tableCC = new ConfigurationCopy(DefaultConfiguration.getInstance());
      opts.tableConfig.forEach(tableCC::set);
      this.tableConf = tableCC;
    } else {
      this.tableConf = DefaultConfiguration.getInstance();
    }

    if (opts.indexCacheSize > 0 || opts.dataCacheSize > 0) {
      ConfigurationCopy cc = tableConf instanceof ConfigurationCopy ? (ConfigurationCopy) tableConf
          : new ConfigurationCopy(tableConf);
      try {
        blockCacheManager = BlockCacheManagerFactory.getClientInstance(cc);
        if (opts.indexCacheSize > 0) {
          cc.set(Property.TSERV_INDEXCACHE_SIZE, Long.toString(opts.indexCacheSize));
        }
        if (opts.dataCacheSize > 0) {
          cc.set(Property.TSERV_DATACACHE_SIZE, Long.toString(opts.dataCacheSize));
        }
        blockCacheManager.start(BlockCacheConfiguration.forTabletServer(cc));
        this.indexCache = blockCacheManager.getBlockCache(CacheType.INDEX);
        this.dataCache = blockCacheManager.getBlockCache(CacheType.DATA);
      } catch (ReflectiveOperationException e) {
        throw new IllegalArgumentException(
            "Configuration does not contain loadable class for block cache manager factory", e);
      }
    }
    if (indexCache == null) {
      this.indexCache = new NoopCache();
    }
    if (this.dataCache == null) {
      this.dataCache = new NoopCache();
    }
    this.cryptoService =
        CryptoFactoryLoader.getServiceForClient(CryptoEnvironment.Scope.TABLE, opts.tableConfig);
  }

  @Override
  public synchronized void fetchColumnFamily(Text col) {
    Preconditions.checkArgument(opts.useSystemIterators,
        "Can only fetch columns when using system iterators");
    super.fetchColumnFamily(col);
  }

  @Override
  public synchronized void fetchColumn(Text colFam, Text colQual) {
    Preconditions.checkArgument(opts.useSystemIterators,
        "Can only fetch columns when using system iterators");
    super.fetchColumn(colFam, colQual);
  }

  @Override
  public void fetchColumn(IteratorSetting.Column column) {
    Preconditions.checkArgument(opts.useSystemIterators,
        "Can only fetch columns when using system iterators");
    super.fetchColumn(column);
  }

  @Override
  public void setClassLoaderContext(String classLoaderContext) {
    throw new UnsupportedOperationException();
  }

  @Override
  public void setRange(Range range) {
    this.range = range;
  }

  @Override
  public Range getRange() {
    return range;
  }

  @Override
  public void setBatchSize(int size) {
    this.batchSize = size;
  }

  @Override
  public int getBatchSize() {
    return batchSize;
  }

  @Override
  public void enableIsolation() {}

  @Override
  public void disableIsolation() {}

  @Override
  public synchronized void setReadaheadThreshold(long batches) {
    Preconditions.checkArgument(batches > 0);
    readaheadThreshold = batches;
  }

  @Override
  public synchronized long getReadaheadThreshold() {
    return readaheadThreshold;
  }

  @Override
  public Authorizations getAuthorizations() {
    return opts.auths;
  }

  @Override
  public void addScanIterator(IteratorSetting cfg) {
    super.addScanIterator(cfg);
  }

  @Override
  public void removeScanIterator(String iteratorName) {
    super.removeScanIterator(iteratorName);
  }

  @Override
  public void updateScanIteratorOption(String iteratorName, String key, String value) {
    super.updateScanIteratorOption(iteratorName, key, value);
  }

  private class IterEnv implements IteratorEnvironment {
    @Override
    public IteratorScope getIteratorScope() {
      return IteratorScope.scan;
    }

    @Override
    public boolean isFullMajorCompaction() {
      return false;
    }

    @Override
    public Authorizations getAuthorizations() {
      return opts.auths;
    }

    @Override
    public boolean isSamplingEnabled() {
      return RFileScanner.this.getSamplerConfiguration() != null;
    }

    @Override
    public SamplerConfiguration getSamplerConfiguration() {
      return RFileScanner.this.getSamplerConfiguration();
    }
  }

  @Override
  public Iterator<Entry<Key,Value>> iterator() {
    try {
      RFileSource[] sources = opts.in.getSources();
      List<SortedKeyValueIterator<Key,Value>> readers = new ArrayList<>(sources.length);

      CacheProvider cacheProvider = new BasicCacheProvider(indexCache, dataCache);

      for (int i = 0; i < sources.length; i++) {
        // TODO may have been a bug with multiple files and caching in older version...
        FSDataInputStream inputStream = (FSDataInputStream) sources[i].getInputStream();
        CachableBuilder cb =
            new CachableBuilder().input(inputStream, "source-" + i).length(sources[i].getLength())
                .conf(opts.in.getConf()).cacheProvider(cacheProvider).cryptoService(cryptoService);
        readers.add(RFile.getReader(cb, sources[i].getRange()));
      }

      if (getSamplerConfiguration() != null) {
        for (int i = 0; i < readers.size(); i++) {
          readers.set(i, ((Reader) readers.get(i))
              .getSample(new SamplerConfigurationImpl(getSamplerConfiguration())));
        }
      }

      SortedKeyValueIterator<Key,Value> iterator;
      if (opts.bounds != null) {
        iterator = new MultiIterator(readers, opts.bounds);
      } else {
        iterator = new MultiIterator(readers, false);
      }

      Set<ByteSequence> families = Collections.emptySet();

      if (opts.useSystemIterators) {
        SortedSet<Column> cols = this.getFetchedColumns();
        families = LocalityGroupUtil.families(cols);
        iterator = SystemIteratorUtil.setupSystemScanIterators(iterator, cols, getAuthorizations(),
            EMPTY_BYTES, tableConf);
      }

      try {
        if (opts.tableConfig != null && !opts.tableConfig.isEmpty()) {
          var ibEnv = IteratorConfigUtil.loadIterConf(IteratorScope.scan, serverSideIteratorList,
              serverSideIteratorOptions, tableConf);
          var iteratorBuilder = ibEnv.env(new IterEnv()).build();
          iterator = IteratorConfigUtil.loadIterators(iterator, iteratorBuilder);
        } else {
          var iteratorBuilder = IteratorBuilder.builder(serverSideIteratorList)
              .opts(serverSideIteratorOptions).env(new IterEnv()).build();
          iterator = IteratorConfigUtil.loadIterators(iterator, iteratorBuilder);
        }
      } catch (IOException e) {
        throw new UncheckedIOException(e);
      }

      iterator.seek(getRange() == null ? EMPTY_RANGE : getRange(), families, !families.isEmpty());
      return new IteratorAdapter(iterator);

    } catch (IOException e) {
      throw new UncheckedIOException(e);
    }
  }

  @Override
  public void close() {
    try {
      for (RFileSource source : opts.in.getSources()) {
        source.getInputStream().close();
      }
    } catch (IOException e) {
      throw new UncheckedIOException(e);
    }
    if (this.blockCacheManager != null) {
      this.blockCacheManager.stop();
    }
  }
}
---------
/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.accumulo.core.client.rfile;

import java.io.IOException;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.Objects;
import java.util.function.Predicate;

import org.apache.accumulo.core.client.rfile.RFile.SummaryFSOptions;
import org.apache.accumulo.core.client.rfile.RFile.SummaryInputArguments;
import org.apache.accumulo.core.client.rfile.RFile.SummaryOptions;
import org.apache.accumulo.core.client.rfile.RFileScannerBuilder.InputArgs;
import org.apache.accumulo.core.client.summary.SummarizerConfiguration;
import org.apache.accumulo.core.client.summary.Summary;
import org.apache.accumulo.core.crypto.CryptoFactoryLoader;
import org.apache.accumulo.core.spi.crypto.CryptoEnvironment;
import org.apache.accumulo.core.spi.crypto.CryptoService;
import org.apache.accumulo.core.summary.Gatherer;
import org.apache.accumulo.core.summary.SummarizerFactory;
import org.apache.accumulo.core.summary.SummaryCollection;
import org.apache.accumulo.core.summary.SummaryReader;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.io.Text;

class RFileSummariesRetriever implements SummaryInputArguments, SummaryFSOptions, SummaryOptions {

  private Predicate<SummarizerConfiguration> summarySelector = sc -> true;
  private Text startRow;
  private InputArgs in;
  private Text endRow;
  private Map<String,String> config = Collections.emptyMap();

  @Override
  public SummaryOptions selectSummaries(Predicate<SummarizerConfiguration> summarySelector) {
    Objects.requireNonNull(summarySelector);
    this.summarySelector = summarySelector;
    return this;
  }

  @Override
  public SummaryOptions startRow(CharSequence startRow) {
    return startRow(new Text(startRow.toString()));
  }

  @Override
  public SummaryOptions startRow(Text startRow) {
    Objects.requireNonNull(startRow);
    this.startRow = startRow;
    return this;
  }

  @Override
  public SummaryOptions endRow(CharSequence endRow) {
    return endRow(new Text(endRow.toString()));
  }

  @Override
  public SummaryOptions endRow(Text endRow) {
    Objects.requireNonNull(endRow);
    this.endRow = endRow;
    return this;
  }

  @Override
  public Collection<Summary> read() throws IOException {
    SummarizerFactory factory = new SummarizerFactory();

    RFileSource[] sources = in.getSources();
    try {
      SummaryCollection all = new SummaryCollection();
      CryptoService cservice =
          CryptoFactoryLoader.getServiceForClient(CryptoEnvironment.Scope.TABLE, config);
      for (int i = 0; i < sources.length; i++) {
        SummaryReader fileSummary = SummaryReader.load(in.getFileSystem().getConf(), sources[i],
            "source-" + i, summarySelector, factory, cservice);
        SummaryCollection sc = fileSummary
            .getSummaries(Collections.singletonList(new Gatherer.RowRange(startRow, endRow)));
        all.merge(sc, factory);
      }
      return all.getSummaries();
    } finally {
      for (RFileSource source : sources) {
        source.getInputStream().close();
      }
    }
  }

  @Override
  public SummaryOptions withFileSystem(FileSystem fs) {
    Objects.requireNonNull(fs);
    this.in.fs = fs;
    return this;
  }

  @Override
  public SummaryOptions from(RFileSource... inputs) {
    Objects.requireNonNull(inputs);
    in = new InputArgs(inputs);
    return this;
  }

  @Override
  public SummaryFSOptions from(String... files) {
    Objects.requireNonNull(files);
    in = new InputArgs(files);
    return this;
  }

  @Override
  public SummaryOptions withTableProperties(Iterable<Map.Entry<String,String>> props) {
    Objects.requireNonNull(props);
    HashMap<String,String> cfg = new HashMap<>();
    for (Map.Entry<String,String> entry : props) {
      cfg.put(entry.getKey(), entry.getValue());
    }
    this.config = cfg;
    return this;
  }

  @Override
  public SummaryOptions withTableProperties(Map<String,String> props) {
    Objects.requireNonNull(props);
    withTableProperties(props.entrySet());
    return this;
  }
}
---------
/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *   https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an
 * "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 * KIND, either express or implied.  See the License for the
 * specific language governing permissions and limitations
 * under the License.
 */
package org.apache.accumulo.core.client.rfile;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;

class FSConfArgs {

  FileSystem fs;
  Configuration conf;

  FileSystem getFileSystem() throws IOException {
    if (fs == null) {
      fs = FileSystem.get(getConf());
    }
    return fs;
  }

  Configuration getConf() throws IOException {
    if (fs != null) {
      return fs.getConf();
    }

    if (conf == null) {
      conf = new Configuration();
    }
    return conf;
  }
}*/
